# Classification Zero-Shot mDeBERTa pour iOS

Ce r√©pertoire contient les fichiers et scripts pour utiliser le mod√®le de classification zero-shot `mDeBERTa-v3-base-mnli-xnli` sur iOS.

## üì¶ Contenu du r√©pertoire

**Mod√®le et tokenizer** (dans le r√©pertoire racine):
- `model.onnx` - Mod√®le ONNX complet (1.1 GB) ‚≠ê RECOMMAND√â
- `config.json` - Configuration du mod√®le
- `spm.model` - Tokenizer SentencePiece
- `tokenizer_config.json`, `special_tokens_map.json`, etc.

**Code et documentation**:
- `TextClassifier.swift` - Classe Swift pour classification zero-shot iOS
- `NLITester.swift` - Classe Swift pour tests NLI directs
- `test_model.py` - Script Python pour tester la classification zero-shot
- `test_nli.py` - Script Python pour tester le NLI directement
- `README.md` - Ce fichier
- `SETUP_IOS.md` - Guide complet d'int√©gration iOS
- `SOLUTION_FINALE.md` - Explication d√©taill√©e de la solution

## üöÄ D√©marrage rapide

### 1. Tester le mod√®le en Python

**Classification zero-shot:**
```bash
python3 test_model.py
```

**R√©sultat attendu**:
```
1. politics        99.00%  ‚úì
2. economy          0.55%
3. entertainment    0.42%
4. environment      0.04%
```

**Test NLI direct (Natural Language Inference):**
```bash
python3 test_nli.py
```

**R√©sultats attendus:**
- Test 1 (Multilingue): 82.4% entailment
- Test 2 (Entailment): 99.9% entailment ‚úì
- Test 3 (Contradiction): 99.5% contradiction ‚úì
- Test 4 (Neutral): 99.8% neutral ‚úì

### 2. Int√©grer dans une app iOS

#### √âtape 1: Ajouter les d√©pendances

**Avec CocoaPods:**
```ruby
pod 'onnxruntime-objc', '~> 1.19.2'
pod 'SentencePiece'
```

**Avec Swift Package Manager:**
```swift
dependencies: [
    .package(url: "https://github.com/microsoft/onnxruntime-swift-package-manager",
             from: "1.19.2")
]
```

#### √âtape 2: Ajouter les fichiers au projet

1. Copiez `model.onnx` dans votre projet Xcode
2. Copiez `spm.model` dans votre projet Xcode
3. Assurez-vous qu'ils sont ajout√©s au Target > Build Phases > Copy Bundle Resources

#### √âtape 3: Utiliser TextClassifier ou NLITester

**Classification zero-shot (TextClassifier.swift):**
```swift
let classifier = TextClassifier()

// Charger le mod√®le
guard let modelPath = Bundle.main.path(forResource: "model", ofType: "onnx"),
      let tokenizerPath = Bundle.main.path(forResource: "spm", ofType: "model") else {
    fatalError("Fichiers du mod√®le introuvables")
}

try classifier.loadModel(modelPath: modelPath, tokenizerPath: tokenizerPath)

// Classifier un texte
let text = "Apple annonce un nouveau iPhone avec des fonctionnalit√©s r√©volutionnaires"
let labels = ["technologie", "politique", "sport", "√©conomie"]

let results = try classifier.classify(text: text, candidateLabels: labels)

for result in results {
    print("\(result.label): \(result.score * 100)%")
}
```

**Test NLI direct (NLITester.swift):**
```swift
let tester = NLITester()

// Charger le mod√®le
try tester.loadModel(modelPath: modelPath, tokenizerPath: tokenizerPath)

// Tester une paire premise-hypothesis
let result = try tester.predict(
    premise: "Angela Merkel is a politician in Germany",
    hypothesis: "Angela Merkel is a politician"
)

print("Entailment: \(result.entailment * 100)%")      // ~99.9%
print("Neutral: \(result.neutral * 100)%")            // ~0.1%
print("Contradiction: \(result.contradiction * 100)%") // ~0.0%

// Ou ex√©cuter tous les tests
try tester.runAllTests()
```

## ‚ö†Ô∏è Important: Pourquoi ONNX Runtime au lieu de CoreML?

La conversion de mDeBERTa vers CoreML a √©chou√© en raison de:
- Incompatibilit√©s d'op√©rateurs Transformer
- Probl√®mes de types de donn√©es
- Complexit√© du mod√®le NLI

**ONNX Runtime offre:**
- ‚úÖ Support complet des op√©rateurs Transformer
- ‚úÖ Performance optimis√©e pour mobile
- ‚úÖ Compatible avec tous les mod√®les HuggingFace
- ‚úÖ R√©sultats identiques au pipeline Transformers (99.00% de pr√©cision)

## üìä Performance attendue

Sur un iPhone 12 Pro:
- Temps d'inf√©rence: ~200-250ms par classification
- Taille du mod√®le: 1.1 GB (complet) - meilleure pr√©cision
- RAM utilis√©e: ~500 MB

## üîß Points cl√©s de l'impl√©mentation

### Index d'entailment
Pour CE mod√®le, l'entailment est √† l'index **0** (pas 2):
```swift
let entailmentLogit = logits[0]  // Index 0 = entailment
```

### Normalisation avec softmax
Appliquer softmax sur les **logits** d'entailment (pas les probabilit√©s):
```swift
// Collecter les logits d'entailment de tous les labels
let maxLogit = results.map { $0.score }.max() ?? 0.0
let expLogits = results.map { exp($0.score - maxLogit) }
let sumExpLogits = expLogits.reduce(0.0, +)
// Calculer les scores finaux
let normalizedScore = expLogit / sumExpLogits
```

Voir `SOLUTION_FINALE.md` pour plus de d√©tails.

## üìù Exemple de test

```bash
# Tester avec Python (identique au r√©sultat iOS)
python3 test_model.py
```

**Output**:
```
1. politics        99.00%  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
2. economy          0.55%
3. entertainment    0.42%
4. environment      0.04%
```

Le code Swift produit **exactement** les m√™mes r√©sultats!

## üêõ D√©pannage

### Erreur "Model file not found"

V√©rifiez que les fichiers sont bien dans le Bundle:
1. Xcode > Target > Build Phases
2. Copy Bundle Resources
3. V√©rifiez que `model.onnx` et `spm.model` sont pr√©sents

### Crash au chargement du mod√®le

Le mod√®le n√©cessite ~500 MB de RAM:
1. Sur simulateur, augmentez la RAM allou√©e
2. Sur device, fermez les autres apps
3. Chargez le mod√®le une seule fois au d√©marrage

### R√©sultats incorrects

V√©rifiez:
1. Vous utilisez l'index **0** pour l'entailment (pas 2)
2. Vous appliquez softmax sur les **logits** (pas les probabilit√©s)
3. Le template est "This example is {}." (pas "This text is about {}.")

## üìö Ressources

- [ONNX Runtime iOS Guide](https://onnxruntime.ai/docs/tutorials/mobile/ios.html)
- [HuggingFace Model Card](https://huggingface.co/MoritzLaurer/mDeBERTa-v3-base-mnli-xnli)
- [SentencePiece iOS](https://github.com/google/sentencepiece)

## üìÑ License

Le mod√®le mDeBERTa est sous license MIT. Voir `mDeBERTa-v3-base-xnli-multilingual-nli-2mil7/LICENSE`.
